{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os, math\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "sns.set()\n",
    "\n",
    "os.chdir('../..')\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA        = Path('data')\n",
    "RAW         = DATA/'raw'\n",
    "INTERIM     = DATA/'interim'\n",
    "PROCESSED   = DATA/'processed'\n",
    "SUBMISSIONS = DATA/'submissions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_weeks, week_num\n",
    "week_labels = get_weeks(day_from=20160104, num_weeks=121)[91:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEURALNET = INTERIM/'neuralnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 1.25 s, total: 2.43 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_feather(NEURALNET/'train_preproc.feather')\n",
    "val = pd.read_feather(NEURALNET/'val_preproc.feather')\n",
    "test = pd.read_feather(NEURALNET/'test_preproc.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge  = pd.read_csv(RAW/'Challenge_20180423.csv', low_memory=False)\n",
    "# customer   = pd.read_csv(RAW/'Customer.csv', low_memory=False)\n",
    "# isin       = pd.read_csv(RAW/'Isin.csv', low_memory=False)\n",
    "# submission = pd.read_csv(RAW/'sample_submission.csv', low_memory=False)\n",
    "# trade      = pd.read_csv(RAW/'Trade.csv', low_memory=False)\n",
    "market     = pd.read_csv(RAW/'Market.csv', low_memory=False)\n",
    "macro      = pd.read_csv(RAW/'MarketData_Macro.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = market[market.DateKey >= week_labels[0]].copy()\n",
    "market['Week'] = market.DateKey.apply(\n",
    "                        lambda x: week_num(week_labels, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsinIdx</th>\n",
       "      <th>DateKey</th>\n",
       "      <th>Price</th>\n",
       "      <th>Yield</th>\n",
       "      <th>ZSpread</th>\n",
       "      <th>Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5109025</th>\n",
       "      <td>1</td>\n",
       "      <td>20171002</td>\n",
       "      <td>116.50</td>\n",
       "      <td>6.606</td>\n",
       "      <td>4.227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109026</th>\n",
       "      <td>7</td>\n",
       "      <td>20171002</td>\n",
       "      <td>119.25</td>\n",
       "      <td>5.255</td>\n",
       "      <td>3.170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109027</th>\n",
       "      <td>15</td>\n",
       "      <td>20171002</td>\n",
       "      <td>114.50</td>\n",
       "      <td>-4.447</td>\n",
       "      <td>-6.303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109028</th>\n",
       "      <td>19</td>\n",
       "      <td>20171002</td>\n",
       "      <td>118.00</td>\n",
       "      <td>-2.032</td>\n",
       "      <td>-15.532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109029</th>\n",
       "      <td>21</td>\n",
       "      <td>20171002</td>\n",
       "      <td>104.50</td>\n",
       "      <td>16.614</td>\n",
       "      <td>-5.168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         IsinIdx   DateKey   Price   Yield  ZSpread  Week\n",
       "5109025        1  20171002  116.50   6.606    4.227     0\n",
       "5109026        7  20171002  119.25   5.255    3.170     0\n",
       "5109027       15  20171002  114.50  -4.447   -6.303     0\n",
       "5109028       19  20171002  118.00  -2.032  -15.532     0\n",
       "5109029       21  20171002  104.50  16.614   -5.168     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "market['Price'] = market.Price - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_mean = market.groupby(['IsinIdx', 'Week'], as_index=False) \\\n",
    "                    ['Price', 'Yield', 'ZSpread'].agg('mean')\n",
    "weeks_std = market.groupby(['IsinIdx', 'Week'], as_index=False) \\\n",
    "                    ['Price', 'Yield', 'ZSpread'].agg({'Price': 'std',\n",
    "                                                       'Yield': 'std',\n",
    "                                                       'ZSpread': 'std'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_weeks = weeks_mean.Week.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dict = {}\n",
    "yield_dict = {}\n",
    "zspread_dict = {}\n",
    "\n",
    "df = weeks_mean.drop_duplicates('IsinIdx')\n",
    "for i in df.IsinIdx:\n",
    "    price_dict[i] = [0] * n_weeks\n",
    "    yield_dict[i] = [0] * n_weeks\n",
    "    zspread_dict[i] = [0] * n_weeks\n",
    "    \n",
    "df = challenge.drop_duplicates('IsinIdx')\n",
    "for i in df.IsinIdx:\n",
    "    price_dict[i] = [0] * n_weeks\n",
    "    yield_dict[i] = [0] * n_weeks\n",
    "    zspread_dict[i] = [0] * n_weeks\n",
    "    \n",
    "for i in train.IsinIdx.unique():\n",
    "    price_dict[i] = [0] * n_weeks\n",
    "    yield_dict[i] = [0] * n_weeks\n",
    "    zspread_dict[i] = [0] * n_weeks\n",
    "    \n",
    "for i in val.IsinIdx.unique():\n",
    "    price_dict[i] = [0] * n_weeks\n",
    "    yield_dict[i] = [0] * n_weeks\n",
    "    zspread_dict[i] = [0] * n_weeks\n",
    "\n",
    "for i in test.IsinIdx.unique():\n",
    "    price_dict[i] = [0] * n_weeks\n",
    "    yield_dict[i] = [0] * n_weeks\n",
    "    zspread_dict[i] = [0] * n_weeks\n",
    "    \n",
    "for i, w, p, y, z in zip(*[weeks_mean[c] for c in \\\n",
    "            ['IsinIdx', 'Week', 'Price', 'Yield', 'ZSpread']]):\n",
    "    price_dict[i][w] = p\n",
    "    yield_dict[i][w] = y\n",
    "    zspread_dict[i][w] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dict_std = {}\n",
    "yield_dict_std = {}\n",
    "zspread_dict_std = {}\n",
    "\n",
    "df = weeks_mean.drop_duplicates('IsinIdx')\n",
    "for i in df.IsinIdx:\n",
    "    price_dict_std[i] = [0] * n_weeks\n",
    "    yield_dict_std[i] = [0] * n_weeks\n",
    "    zspread_dict_std[i] = [0] * n_weeks\n",
    "    \n",
    "df = challenge.drop_duplicates('IsinIdx')\n",
    "for i in df.IsinIdx:\n",
    "    price_dict_std[i] = [0] * n_weeks\n",
    "    yield_dict_std[i] = [0] * n_weeks\n",
    "    zspread_dict_std[i] = [0] * n_weeks\n",
    "    \n",
    "for i in train.IsinIdx.unique():\n",
    "    price_dict_std[i] = [0] * n_weeks\n",
    "    yield_dict_std[i] = [0] * n_weeks\n",
    "    zspread_dict_std[i] = [0] * n_weeks\n",
    "    \n",
    "for i in val.IsinIdx.unique():\n",
    "    price_dict_std[i] = [0] * n_weeks\n",
    "    yield_dict_std[i] = [0] * n_weeks\n",
    "    zspread_dict_std[i] = [0] * n_weeks\n",
    "\n",
    "for i in test.IsinIdx.unique():\n",
    "    price_dict_std[i] = [0] * n_weeks\n",
    "    yield_dict_std[i] = [0] * n_weeks\n",
    "    zspread_dict[i] = [0] * n_weeks\n",
    "    \n",
    "for i, w, p, y, z in zip(*[weeks_std[c] for c in \\\n",
    "            ['IsinIdx', 'Week', 'Price', 'Yield', 'ZSpread']]):\n",
    "    price_dict_std[i][w] = p\n",
    "    yield_dict_std[i][w] = y\n",
    "    zspread_dict_std[i][w] = z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.structurednet import shift_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_sequences(prices, yields, zspreads, \n",
    "                   prices_std, yields_std, zspreads_std,\n",
    "                   i, w, n_weeks):\n",
    "    return [shift_right(prices[i], w, n_weeks), \n",
    "            shift_right(prices_std[i], w, n_weeks),\n",
    "            shift_right(yields[i], w, n_weeks),\n",
    "            shift_right(yields_std[i], w, n_weeks),\n",
    "            shift_right(zspreads[i], w, n_weeks),\n",
    "            shift_right(zspreads_std[i], w, n_weeks),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seqs(df, prices, yields, zspreads, \n",
    "                   prices_std, yields_std, zspreads_std, n_weeks):\n",
    "    return np.array([roll_sequences(prices, yields, zspreads, \n",
    "                   prices_std, yields_std, zspreads_std,\n",
    "                   i, w, n_weeks) \\\n",
    "                     for i,w in tqdm_notebook(zip(df.IsinIdx, \n",
    "                     df.Week), total=len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6449b223b5a4452af2aa77851c4ee2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8102750), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-1c839ed38cb9>\u001b[0m in \u001b[0;36mextract_seqs\u001b[0;34m(df, prices, yields, zspreads, prices_std, yields_std, zspreads_std, n_weeks)\u001b[0m\n\u001b[1;32m      5\u001b[0m                    i, w, n_weeks) \\\n\u001b[1;32m      6\u001b[0m                      for i,w in tqdm_notebook(zip(df.IsinIdx, \n\u001b[0;32m----> 7\u001b[0;31m                      df.Week), total=len(df))])\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_weeks = len(week_labels)\n",
    "train_seqs = extract_seqs(train, price_dict, yield_dict, \n",
    "                          zspread_dict, \n",
    "                   price_dict_std, yield_dict_std, zspread_dict_std, n_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "val_seqs = extract_seqs(val, transactions, buysells, \n",
    "                              customers, isins, n_weeks)\n",
    "test_seqs = extract_seqs(test, transactions, buysells, \n",
    "                              customers, isins, n_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "with open(NEURALNET/'market_train_seqs.pkl', 'wb') as f:\n",
    "    pickle.dump(train_seqs, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(NEURALNET/'market_val_seqs.pkl', 'wb') as f:\n",
    "    pickle.dump(val_seqs, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(NEURALNET/'market_test_seqs.pkl', 'wb') as f:\n",
    "    pickle.dump(test_seqs, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from src.structured_lstm import MultimodalDataset, MultimodalNet, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "with open(NEURALNET/'train_seqs.pkl', 'rb') as f:\n",
    "    orig_train_seqs = pickle.load(f)\n",
    "with open(NEURALNET/'val_seqs.pkl', 'rb') as f:\n",
    "    orig_val_seqs = pickle.load(f)\n",
    "with open(NEURALNET/'test_seqs.pkl', 'rb') as f:\n",
    "    orig_test_seqs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_seqs.shape, train_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([orig_train_seqs, train_seqs]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = np.concatenate([orig_train_seqs, train_seqs])\n",
    "val_seqs = np.concatenate([orig_val_seqs, val_seqs])\n",
    "test_seqs = np.concatenate([orig_test_seqs, test_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_ds = MultimodalDataset(train[cat_cols], train[num_cols],\n",
    "                             train_seqs, train[target_col])\n",
    "val_ds = MultimodalDataset(val[cat_cols], val[num_cols],\n",
    "                             val_seqs, val[target_col])\n",
    "test_ds = MultimodalDataset(test[cat_cols], test[num_cols],\n",
    "                             test_seqs, test[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Sector', 'Subsector', 'Region_x', 'Country', \n",
    "            'TickerIdx', 'Seniority', 'Currency', 'ActivityGroup', \n",
    "            'Region_y', 'Activity', 'RiskCaptain', 'Owner', \n",
    "            'IndustrySector', 'IndustrySubgroup', 'MarketIssue', 'CouponType',\n",
    "            'CompositeRatingCat', 'CustomerIdxCat', 'IsinIdxCat', 'BuySellCat']\n",
    "num_cols = ['ActualMaturityDateKey', 'IssueDateKey', 'IssuedAmount', \n",
    "            'BondDuration', 'BondRemaining', 'BondLife', \n",
    "            'Day', 'CompositeRating', 'BuySellCont',\n",
    "            \n",
    "            'DaysSinceBuySell', 'DaysSinceTransaction', 'DaysSinceCustomerActivity',\n",
    "            'DaysSinceBondActivity', 'DaysCountBuySell', 'DaysCountTransaction',\n",
    "            'DaysCountCustomerActivity', 'DaysCountBondActivity', 'SVD_CustomerBias',\n",
    "            'SVD_IsinBuySellBias', 'SVD_Recommend', 'SVD_CustomerFactor00',\n",
    "            'SVD_CustomerFactor01', 'SVD_CustomerFactor02', 'SVD_CustomerFactor03',\n",
    "            'SVD_CustomerFactor04', 'SVD_CustomerFactor05', 'SVD_CustomerFactor06',\n",
    "            'SVD_CustomerFactor07', 'SVD_CustomerFactor08', 'SVD_CustomerFactor09',\n",
    "            'SVD_CustomerFactor10', 'SVD_CustomerFactor11', 'SVD_CustomerFactor12',\n",
    "            'SVD_CustomerFactor13', 'SVD_CustomerFactor14']\n",
    "id_cols = ['CustomerIdx', 'IsinIdx', 'BuySell']\n",
    "target_col = 'CustomerInterest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from src.structured_lstm import MultimodalDataset, MultimodalNet, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_ds = MultimodalDataset(train[cat_cols], train[num_cols],\n",
    "                             train_seqs, train[target_col])\n",
    "val_ds = MultimodalDataset(val[cat_cols], val[num_cols],\n",
    "                             val_seqs, val[target_col])\n",
    "test_ds = MultimodalDataset(test[cat_cols], test[num_cols],\n",
    "                             test_seqs, test[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_ds = torch.utils.data.ConcatDataset([train_ds, val_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_train_dl = DataLoader(all_train_ds, batch_size=128, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultimodalNet(emb_szs, n_cont=len(num_cols), emb_drop=0.2,\n",
    "                      szs=[1000,500], drops=[0.5, 0.5],\n",
    "                      rnn_hidden_sz=64, rnn_input_sz=10, rnn_n_layers=2,\n",
    "                      rnn_drop=0.5)\n",
    "\n",
    "if USE_CUDA: model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model, train_losses, _, _ = train_model(\n",
    "                model, all_train_dl, None, optimizer, criterion,\n",
    "                n_epochs=1, USE_CUDA=USE_CUDA, print_every=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
