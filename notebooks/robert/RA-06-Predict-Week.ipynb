{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os, math\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from pandas_summary import DataFrameSummary\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "sns.set()\n",
    "\n",
    "os.chdir('../..')\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA        = Path('data')\n",
    "RAW         = DATA/'raw'\n",
    "INTERIM     = DATA/'interim'\n",
    "PROCESSED   = DATA/'processed'\n",
    "SUBMISSIONS = DATA/'submissions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge  = pd.read_csv(RAW/'Challenge_20180423.csv', low_memory=False)\n",
    "customer   = pd.read_csv(RAW/'Customer.csv', low_memory=False)\n",
    "isin       = pd.read_csv(RAW/'Isin.csv', low_memory=False)\n",
    "submission = pd.read_csv(RAW/'sample_submission.csv', low_memory=False)\n",
    "trade      = pd.read_csv(RAW/'Trade.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import make_val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 s, sys: 144 ms, total: 31.7 s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "week_0416 = make_val_set(trade[trade.TradeDateKey >= 20180416],\n",
    "                         challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    476311\n",
       "1.0     17279\n",
       "Name: CustomerInterest, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_0416.CustomerInterest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03500678700946129"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.5 % of positive labels in val set\n",
    "17279 / len(week_0416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 s, sys: 100 ms, total: 31.4 s\n",
      "Wall time: 31.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "week_0409 = make_val_set(trade[(trade.TradeDateKey >= 20180409) &\n",
    "                               (trade.TradeDateKey <  20180416)],\n",
    "                         challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    475374\n",
       "1.0     17532\n",
       "Name: CustomerInterest, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_0409.CustomerInterest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035568647977504836"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.55 % of positive labels in train set\n",
    "17532 / len(week_0409)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['BuySell', 'Sector', 'Subsector', 'Region_x', 'Country', \n",
    "            'TickerIdx', 'Seniority', 'Currency', 'ActivityGroup', \n",
    "            'Region_y', 'Activity', 'RiskCaptain', 'Owner', 'CompositeRating', \n",
    "            'IndustrySector', 'IndustrySubgroup', 'MarketIssue', 'CouponType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import add_datediffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 852 ms, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "add_datediffs(week_0409, trade)\n",
    "add_datediffs(week_0416, trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_0409.reset_index().to_feather(PROCESSED/'week_0409_val.feather')\n",
    "week_0416.reset_index().to_feather(PROCESSED/'week_0416_val.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = week_0409\n",
    "val   = week_0416\n",
    "test  = pd.read_feather(PROCESSED/'test_datediffs.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import preprocessing_pipeline\n",
    "test  = preprocessing_pipeline(test, customer, isin, trade)\n",
    "val   = preprocessing_pipeline(val, customer, isin, trade)\n",
    "train = preprocessing_pipeline(train, customer, isin, trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['TradeDateKey', 'CustomerIdx', 'IsinIdx']\n",
    "target_col = 'CustomerInterest'\n",
    "pred_col = 'PredictionIdx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('DateKey', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((492906, 29), (493590, 29), (484758, 30))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import apply_cats\n",
    "for col in cat_cols:\n",
    "    test[col] = test[col].astype('category').cat.as_ordered()\n",
    "apply_cats(train, test)\n",
    "apply_cats(val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    train[col] = train[col].cat.codes\n",
    "    val[col] = val[col].cat.codes\n",
    "    test[col] = test[col].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, pprint\n",
    "pp = pprint.PrettyPrinter(indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# globals: [cat_indices]\n",
    "def fit_model(model, model_name, X_trn, y_trn, X_val, y_val):\n",
    "    if model_name in ['XGBClassifier', 'LGBMClassifier']:\n",
    "        model.fit(X_trn, y_trn, \n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  early_stopping_rounds=30,\n",
    "                  eval_metric='auc')\n",
    "    elif model_name == 'CatBoostClassifier':\n",
    "        model.fit(X_trn, y_trn, \n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  use_best_model=True,\n",
    "                  cat_features=cat_indices)\n",
    "    else:\n",
    "        model.fit(X_trn, y_trn)\n",
    "        \n",
    "def calculate_metrics(model, metrics, X_trn, y_trn, X_val, y_val):\n",
    "    metric_function = {'auc': roc_auc_score}\n",
    "    dset = {'trn': {'X': X_trn, 'y': y_trn},\n",
    "            'val': {'X': X_val, 'y': y_val}}\n",
    "    \n",
    "    for d in dset:\n",
    "        y_pred = model.predict_proba(dset[d]['X'])[:,1]\n",
    "        for m in metrics:\n",
    "            metrics[m][d] += [metric_function[m](dset[d]['y'], y_pred)]\n",
    "                \n",
    "    pp.pprint(metrics)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X_train, y_train, X_val, y_val, X_test, \n",
    "              metric_names, results=None, dataset_desc='', params_desc=''):\n",
    "    model_name = str(model.__class__).split('.')[-1].replace('>','').replace(\"'\",'')\n",
    "    print(model_name, '\\n')\n",
    "    if results is None: results = pd.DataFrame()\n",
    "    metrics = {metric: {'trn': [], 'val': []} for metric in metric_names}\n",
    "    y_test = np.zeros((len(X_test)))\n",
    "    start = time.time()\n",
    "    \n",
    "    fit_model(model, model_name, X_train, y_train, X_val, y_val)\n",
    "    calculate_metrics(model, metrics, X_train, y_train, X_val, y_val)\n",
    "    y_test = model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "    end = time.time()\n",
    "    means = {f'{d}_{m}_mean': np.mean(metrics[m][d]) for m in metrics \\\n",
    "                                                     for d in metrics[m]}\n",
    "    stds  = {f'{d}_{m}_std': np.std(metrics[m][d]) for m in metrics \\\n",
    "                                                     for d in metrics[m]}\n",
    "    metadata = {'model': model_name, 'dataset': dataset_desc,\n",
    "                'params': params_desc, 'time': round(end - start, 2)}\n",
    "    pp.pprint(means)\n",
    "    results = results.append(pd.Series({**metadata, **means, **stds}), ignore_index=True)\n",
    "    return y_test, metrics, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "metric_names = ['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier \n",
      "\n",
      "[1]\tvalid_0's auc: 0.818243\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[2]\tvalid_0's auc: 0.818344\n",
      "[3]\tvalid_0's auc: 0.818317\n",
      "[4]\tvalid_0's auc: 0.820228\n",
      "[5]\tvalid_0's auc: 0.820721\n",
      "[6]\tvalid_0's auc: 0.820625\n",
      "[7]\tvalid_0's auc: 0.83575\n",
      "[8]\tvalid_0's auc: 0.835687\n",
      "[9]\tvalid_0's auc: 0.837461\n",
      "[10]\tvalid_0's auc: 0.83852\n",
      "[11]\tvalid_0's auc: 0.838576\n",
      "[12]\tvalid_0's auc: 0.838712\n",
      "[13]\tvalid_0's auc: 0.839013\n",
      "[14]\tvalid_0's auc: 0.839285\n",
      "[15]\tvalid_0's auc: 0.839157\n",
      "[16]\tvalid_0's auc: 0.841013\n",
      "[17]\tvalid_0's auc: 0.841273\n",
      "[18]\tvalid_0's auc: 0.841472\n",
      "[19]\tvalid_0's auc: 0.841413\n",
      "[20]\tvalid_0's auc: 0.841734\n",
      "[21]\tvalid_0's auc: 0.841835\n",
      "[22]\tvalid_0's auc: 0.841731\n",
      "[23]\tvalid_0's auc: 0.841948\n",
      "[24]\tvalid_0's auc: 0.842023\n",
      "[25]\tvalid_0's auc: 0.842796\n",
      "[26]\tvalid_0's auc: 0.843562\n",
      "[27]\tvalid_0's auc: 0.844094\n",
      "[28]\tvalid_0's auc: 0.844029\n",
      "[29]\tvalid_0's auc: 0.844186\n",
      "[30]\tvalid_0's auc: 0.844152\n",
      "[31]\tvalid_0's auc: 0.845846\n",
      "[32]\tvalid_0's auc: 0.846581\n",
      "[33]\tvalid_0's auc: 0.846553\n",
      "[34]\tvalid_0's auc: 0.846504\n",
      "[35]\tvalid_0's auc: 0.846525\n",
      "[36]\tvalid_0's auc: 0.847915\n",
      "[37]\tvalid_0's auc: 0.848009\n",
      "[38]\tvalid_0's auc: 0.848098\n",
      "[39]\tvalid_0's auc: 0.848652\n",
      "[40]\tvalid_0's auc: 0.849542\n",
      "[41]\tvalid_0's auc: 0.849759\n",
      "[42]\tvalid_0's auc: 0.849943\n",
      "[43]\tvalid_0's auc: 0.849981\n",
      "[44]\tvalid_0's auc: 0.8507\n",
      "[45]\tvalid_0's auc: 0.851264\n",
      "[46]\tvalid_0's auc: 0.851325\n",
      "[47]\tvalid_0's auc: 0.851468\n",
      "[48]\tvalid_0's auc: 0.851874\n",
      "[49]\tvalid_0's auc: 0.852075\n",
      "[50]\tvalid_0's auc: 0.852466\n",
      "[51]\tvalid_0's auc: 0.852612\n",
      "[52]\tvalid_0's auc: 0.852875\n",
      "[53]\tvalid_0's auc: 0.85295\n",
      "[54]\tvalid_0's auc: 0.853214\n",
      "[55]\tvalid_0's auc: 0.853474\n",
      "[56]\tvalid_0's auc: 0.8538\n",
      "[57]\tvalid_0's auc: 0.853971\n",
      "[58]\tvalid_0's auc: 0.854333\n",
      "[59]\tvalid_0's auc: 0.854411\n",
      "[60]\tvalid_0's auc: 0.854383\n",
      "[61]\tvalid_0's auc: 0.854396\n",
      "[62]\tvalid_0's auc: 0.854292\n",
      "[63]\tvalid_0's auc: 0.854404\n",
      "[64]\tvalid_0's auc: 0.854448\n",
      "[65]\tvalid_0's auc: 0.854384\n",
      "[66]\tvalid_0's auc: 0.854498\n",
      "[67]\tvalid_0's auc: 0.854415\n",
      "[68]\tvalid_0's auc: 0.854149\n",
      "[69]\tvalid_0's auc: 0.854166\n",
      "[70]\tvalid_0's auc: 0.854099\n",
      "[71]\tvalid_0's auc: 0.85388\n",
      "[72]\tvalid_0's auc: 0.853768\n",
      "[73]\tvalid_0's auc: 0.853759\n",
      "[74]\tvalid_0's auc: 0.8538\n",
      "[75]\tvalid_0's auc: 0.853711\n",
      "[76]\tvalid_0's auc: 0.853716\n",
      "[77]\tvalid_0's auc: 0.853741\n",
      "[78]\tvalid_0's auc: 0.853007\n",
      "[79]\tvalid_0's auc: 0.852983\n",
      "[80]\tvalid_0's auc: 0.85289\n",
      "[81]\tvalid_0's auc: 0.852886\n",
      "[82]\tvalid_0's auc: 0.853056\n",
      "[83]\tvalid_0's auc: 0.852992\n",
      "[84]\tvalid_0's auc: 0.852878\n",
      "[85]\tvalid_0's auc: 0.852967\n",
      "[86]\tvalid_0's auc: 0.852917\n",
      "[87]\tvalid_0's auc: 0.853063\n",
      "[88]\tvalid_0's auc: 0.852581\n",
      "[89]\tvalid_0's auc: 0.852613\n",
      "[90]\tvalid_0's auc: 0.852621\n",
      "[91]\tvalid_0's auc: 0.852492\n",
      "[92]\tvalid_0's auc: 0.852488\n",
      "[93]\tvalid_0's auc: 0.852486\n",
      "[94]\tvalid_0's auc: 0.852535\n",
      "[95]\tvalid_0's auc: 0.85248\n",
      "[96]\tvalid_0's auc: 0.85252\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.854498\n",
      "{'auc': {'trn': [0.871635890624965], 'val': [0.8544983380540635]}}\n",
      "\n",
      "{'trn_auc_mean': 0.871635890624965, 'val_auc_mean': 0.8544983380540635}\n",
      "CPU times: user 25.5 s, sys: 564 ms, total: 26.1 s\n",
      "Wall time: 5.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test, metrics, results = run_model(\n",
    "            LGBMClassifier(n_estimators=1000),\n",
    "            train.drop(id_cols + [target_col], axis=1),\n",
    "            train[target_col],\n",
    "            val.drop(id_cols + [target_col], axis=1),\n",
    "            val[target_col],\n",
    "            test.drop(id_cols + [target_col, pred_col], axis=1),\n",
    "            metric_names, None, \n",
    "            params_desc='n_estimators=1000',\n",
    "            dataset_desc='week_datediffs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>time</th>\n",
       "      <th>trn_auc_mean</th>\n",
       "      <th>trn_auc_std</th>\n",
       "      <th>val_auc_mean</th>\n",
       "      <th>val_auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>week_datediffs</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>n_estimators=1000</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.871636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.854498</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset           model             params  time  trn_auc_mean  \\\n",
       "0  week_datediffs  LGBMClassifier  n_estimators=1000  5.76      0.871636   \n",
       "\n",
       "   trn_auc_std  val_auc_mean  val_auc_std  \n",
       "0          0.0      0.854498          0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target_col] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(RAW/'sample_submission.csv', low_memory=False)\n",
    "submission = pd.merge(submission[['PredictionIdx']], test[['PredictionIdx', target_col]], how='left', on='PredictionIdx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    484758.000000\n",
       "mean          0.082337\n",
       "std           0.103445\n",
       "min           0.002977\n",
       "25%           0.011680\n",
       "50%           0.020786\n",
       "75%           0.198452\n",
       "max           0.824155\n",
       "Name: CustomerInterest, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[target_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionIdx</th>\n",
       "      <th>CustomerInterest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1e0d80784</td>\n",
       "      <td>0.151956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2cc6cc2a8</td>\n",
       "      <td>0.047319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a8e94f6344</td>\n",
       "      <td>0.190352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>758bae1e35</td>\n",
       "      <td>0.252158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02ab378ee8</td>\n",
       "      <td>0.211535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PredictionIdx  CustomerInterest\n",
       "0    a1e0d80784          0.151956\n",
       "1    c2cc6cc2a8          0.047319\n",
       "2    a8e94f6344          0.190352\n",
       "3    758bae1e35          0.252158\n",
       "4    02ab378ee8          0.211535"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(SUBMISSIONS/'lgbm_week_datediffs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
